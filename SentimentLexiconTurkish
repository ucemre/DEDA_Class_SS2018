#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue May 29 10:43:15 2018

@author: cemre
"""
import pandas as ps

from bs4 import BeautifulSoup

import requests

import string
from nltk.corpus import stopwords

import matplotlib.pyplot as plt

from wordcloud import (WordCloud, get_single_color_func)

from PIL import Image

from googletrans import Translator

translator = Translator()

# Accessing speech texts
url = "https://www.tccb.gov.tr/konusmalar/353/94021/kudus-e-destek-mitinginde-yaptiklari-konusma.html"

rte = requests.get(url)  
html = rte.text  
soup = BeautifulSoup(html, 'html.parser')
print(soup.find('div', {"id" : "divContentArea"}).text)

text = str(soup.find('div', {"id" : "divContentArea"}).text)
# Extracting Title and date of the speech
title = str(soup.find('h1').text)
date_stamp = str(soup.find('h6').text)

#Translating speech title in English
title_list = title.split()
title_len = []

for tword in title_list:
    trs = translator.translate(tword, src = 'tr', dest = 'en')
    title_len.append(trs.text)

del title_len[-2:]

title_en = ' '.join(title_len)

#Removing the punctuation and making the words lowercase
translator = str.maketrans('', '', string.punctuation)
#print(text.translate(translator))

text = text.translate(translator).lower()

# Creating a dictionary for the words in the text

dat = list(text.split())
dict1 = {}
for i in range(len(dat)):
    word = dat[i]
    dict1[word] = dat.count(word)
 
#Checking the listed stopwords in NLTK package
#stop_words = stopwords.words('turkish')

#Importing the extended stopwords list
#Resource: https://github.com/ahmetax/trstop/blob/master/dosyalar/derlemtr2016-10000.txt
stoplist = open("swNI.csv", "r")
stopwords = stoplist.readlines()
stopwords = [i.replace('"', '') for i in stopwords]
stopwords = [i.replace('\n', '') for i in stopwords]

print(stopwords)

#Removing stopwords
keys = list(dict1)
keys = [i.replace('"', '') for i in keys]
keys = [i.replace("'", '') for i in keys]
filtered_words = [word for word in keys if word not in stopwords]
filered_words = [i.replace('i̇', 'i') for i in filtered_words]
dict2 = dict((k, dict1[k]) for k in filtered_words if k in filtered_words)


def SequenceSelection(dictionary, length, startindex = 0): 
    
    lengthDict = len(dictionary)
    if length > lengthDict:
        return print("length is longer than dictionary length");
    else:
        d = dictionary
        items = [(v, k) for k, v in d.items()]
        items.sort()
        items.reverse()   
        itemsOut = [(k, v) for v, k in items]
    
        highest = itemsOut[startindex:startindex + length]
        dd = dict(highest)
        wanted_keys = dd.keys()
        dictshow = dict((k, d[k]) for k in wanted_keys if k in d)

        return dictshow;
    
dictshow = SequenceSelection(dictionary = dict2, length = 7, startindex = 0)

# Visualizing the frequent words in Turkish

n = range(len(dictshow))
plt.bar(n, dictshow.values(), align='center')
plt.xticks(n, dictshow.keys())
plt.title("Most frequent Words")
plt.savefig("FrequentWords.png", transparent=True)

#Translating most frequest words into English
eng_FQwords = []

for fqword in list(dictshow):
    trs = translator.translate(fqword, src = 'tr', dest = 'en')
    eng_FQwords.append(trs.text)
    
print(eng_FQwords)

# Visualising the most frequent words in English
n = range(len(eng_FQwords))
plt.bar(n, dictshow.values(), align='center')
plt.xticks(n, eng_FQwords, rotation = 45)
plt.title("Most frequent Words")  

########### IN PROGRESSSSSS
#Creating color codes for the word cloud
trlist = open("Turkce_Duygu_Sozlugu_V1.csv", "r")
tr_color = trlist.readlines()

tr_color = [i.split(';') for i in tr_color]

df = ps.DataFrame(data=tr_color)
df = df.drop(df.columns[[2, 3,4,5]], axis=1)
df = df.drop([0, 12995, 5492, 13715]) #df cleaning

df[1] = df[1].apply(ps.to_numeric)
df[0] = df[0].apply(ps.to_str)

pos_words = df.loc[df[1] == 1]
neg_words = df.loc[df[1] == -1]

col_to_words = {}

if (filtered_WC )


#####################


# Creating the word cloud of filtered words in Turkish
###### Face of erdogan as a mask IN PROGRESS ######
import numpy as np
from os import path
import os
root_path = os.getcwd()


rte_mask = np.array(Image.open(path.join(root_path, "rte.png")))
ampul_mask = np.array(Image.open(path.join(root_path, "ampul.png")))


filtered_WC = ' '.join(filtered_words)
filtered_WC = filtered_WC.replace('i̇', 'i')
filtered_WC = filtered_WC.replace('"', '')
filtered_WC = filtered_WC.replace("'", '')
wordcloud_FW = WordCloud(background_color='white', mask=rte_mask, mode='RGBA').generate(filtered_WC)

wordcloud_FW = WordCloud(background_color='white', mask = ampul_mask).generate(filtered_WC)

plt.figure()
plt.imshow(wordcloud_FW, interpolation='bilinear')
plt.axis("off")
#plt.imshow(ampul_mask, cmap=plt.cm.gray, interpolation='bilinear')
#plt.axis("off")
plt.title(title + " - " + date_stamp)
plt.show()
plt.savefig(date_stamp+"_Wordcloud_TR.png", transparent=True)

# Creating the word cloud of filtered words in english
eng_fil_words = []

for filword in filtered_words:
    trs = translator.translate(filword, src = 'tr', dest = 'en')
    eng_fil_words.append(trs.text)
    print(eng_fil_words)
    eng_fil_words

filtered_WC_eng = ' '.join(eng_fil_words)
#filtered_WC_eng = filtered_WC.replace('i̇', 'i')
filtered_WC_eng = filtered_WC_eng.replace('"', '')
filtered_WC_eng = filtered_WC_eng.replace("'", '')
wordcloud_FW_eng = WordCloud(background_color='white').generate(filtered_WC_eng)

plt.imshow(wordcloud_FW_eng, interpolation='bilinear')
plt.title(title_en + " on " + date_stamp)
plt.axis("off")
plt.figure()
plt.imshow(rte_mask, cmap=plt.cm.gray, interpolation='bilinear')
plt.axis("off")
plt.savefig(date_stamp+"_Wordcloud_EN.png", transparent=True)
